{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "import sklearn.covariance\n",
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "# plotting stuff\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import collections\n",
    "import seaborn as sb\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8, 6\n",
    "from timeit import default_timer as timer\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_3_drop = False\n",
    "gen_4_drop = False\n",
    "precip_drop = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = \"/Users/hn/Desktop/Desktop/Kirti/check_point/analogs/\"\n",
    "out_dir = \"/Users/hn/Desktop/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine needed columns\n",
    "If we want to drop some columns like `Gen_4`, `preci`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['medianDoY', 'NumLarvaGens_Aug', 'mean_escaped_Gen1', 'mean_escaped_Gen2', 'mean_escaped_Gen3', 'mean_escaped_Gen4', 'mean_precip', 'mean_gdd']\n"
     ]
    }
   ],
   "source": [
    "numeric_feat = ['medianDoY', 'NumLarvaGens_Aug', \n",
    "                'mean_escaped_Gen1', 'mean_escaped_Gen2', 'mean_escaped_Gen3', 'mean_escaped_Gen4', \n",
    "                'mean_precip', 'mean_gdd']\n",
    "\n",
    "non_numeric_feat = ['year', 'location', 'ClimateScenario']\n",
    "\n",
    "if gen_3_drop == True:\n",
    "    numeric_feat.remove('mean_escaped_Gen3')\n",
    "\n",
    "if gen_4_drop == True:\n",
    "    numeric_feat.remove('mean_escaped_Gen4')\n",
    "\n",
    "if precip_drop == True:\n",
    "    numeric_feat.remove('mean_precip')\n",
    "\n",
    "print(numeric_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>location</th>\n",
       "      <th>ClimateScenario</th>\n",
       "      <th>medianDoY</th>\n",
       "      <th>NumLarvaGens_Aug</th>\n",
       "      <th>mean_escaped_Gen1</th>\n",
       "      <th>mean_escaped_Gen2</th>\n",
       "      <th>mean_escaped_Gen3</th>\n",
       "      <th>mean_escaped_Gen4</th>\n",
       "      <th>mean_precip</th>\n",
       "      <th>mean_gdd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>32.46875_-109.90625</td>\n",
       "      <td>observed</td>\n",
       "      <td>68</td>\n",
       "      <td>2.939262</td>\n",
       "      <td>1.319697</td>\n",
       "      <td>7.080458</td>\n",
       "      <td>1.348167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.525</td>\n",
       "      <td>4821.668922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979</td>\n",
       "      <td>32.46875_-109.96875</td>\n",
       "      <td>observed</td>\n",
       "      <td>68</td>\n",
       "      <td>2.946050</td>\n",
       "      <td>1.245847</td>\n",
       "      <td>7.104994</td>\n",
       "      <td>1.396980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>303.925</td>\n",
       "      <td>4831.770062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year             location ClimateScenario  medianDoY  NumLarvaGens_Aug  \\\n",
       "0  1979  32.46875_-109.90625        observed         68          2.939262   \n",
       "1  1979  32.46875_-109.96875        observed         68          2.946050   \n",
       "\n",
       "   mean_escaped_Gen1  mean_escaped_Gen2  mean_escaped_Gen3  mean_escaped_Gen4  \\\n",
       "0           1.319697           7.080458           1.348167                0.0   \n",
       "1           1.245847           7.104994           1.396980                0.0   \n",
       "\n",
       "   mean_precip     mean_gdd  \n",
       "0      300.525  4821.668922  \n",
       "1      303.925  4831.770062  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_orig = pd.read_csv(in_dir + \"all_data_usa.csv\")\n",
    "hist_orig = hist_orig.loc[:, non_numeric_feat + numeric_feat] # drop unwanted columns\n",
    "hist_orig.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_orig = pd.read_csv(in_dir + \"averaged_data_rcp45.csv\")\n",
    "future_orig = future_orig.loc[:, non_numeric_feat + numeric_feat] # drop unwanted columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_locations(all_dt, local_dt):\n",
    "    # list of unique locations in the data\n",
    "    local_sites = local_dt.location.unique()\n",
    "    all_sites = all_dt.location.unique()\n",
    "\n",
    "    # find the local sites that exist in all_usa_data\n",
    "    local_sites = np.intersect1d(local_sites, all_sites)\n",
    "\n",
    "    # select the rows corresponding to existing sites\n",
    "    local_dt = local_dt.loc[local_dt['location'].isin(local_sites)]\n",
    "    return (local_dt)\n",
    "\n",
    "def detect_effective_compon(matriks):\n",
    "    n_comp = matriks.shape[1]\n",
    "    pca = PCA(n_components = n_comp)\n",
    "    pca.fit(matriks)\n",
    "    return (len(pca.explained_variance_[pca.explained_variance_ > 0.01])) \n",
    "\n",
    "def create_colnames(NN_count):\n",
    "    year_loc_cols = pd.Series(['year_NN_', 'location_NN_'] * NN_count)\n",
    "    numbers = pd.Series(np.arange(1, NN_count+1).repeat(2))\n",
    "    year_loc_cols = year_loc_cols.astype(str) + numbers.astype(str)\n",
    "    year_loc_cols = list(year_loc_cols)\n",
    "    \n",
    "    dist_cols = pd.Series(['dist_NN_'] * NN_count)\n",
    "    dist_cols = list(pd.Series(['dist_NN_'] * NN_count) + pd.Series(np.arange(1, NN_count+1)).astype(str))\n",
    "    return (year_loc_cols, dist_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver\n",
    "\n",
    "\n",
    "#### Filter the locations\n",
    "Some locations in local data are not in all USA. So, here we choose the local (future) data in whose\n",
    "sites do exist in all_usa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_orig = filter_locations(hist_orig, future_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>location</th>\n",
       "      <th>ClimateScenario</th>\n",
       "      <th>medianDoY</th>\n",
       "      <th>NumLarvaGens_Aug</th>\n",
       "      <th>mean_escaped_Gen1</th>\n",
       "      <th>mean_escaped_Gen2</th>\n",
       "      <th>mean_escaped_Gen3</th>\n",
       "      <th>mean_escaped_Gen4</th>\n",
       "      <th>mean_precip</th>\n",
       "      <th>mean_gdd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>ensembe_mean</td>\n",
       "      <td>92</td>\n",
       "      <td>2.336201</td>\n",
       "      <td>24.035184</td>\n",
       "      <td>27.50817</td>\n",
       "      <td>2.912981</td>\n",
       "      <td>0.027137</td>\n",
       "      <td>260.75</td>\n",
       "      <td>3623.723188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2027</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>ensembe_mean</td>\n",
       "      <td>93</td>\n",
       "      <td>2.428946</td>\n",
       "      <td>26.711047</td>\n",
       "      <td>30.58016</td>\n",
       "      <td>2.788000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>245.40</td>\n",
       "      <td>3713.421219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year             location ClimateScenario  medianDoY  NumLarvaGens_Aug  \\\n",
       "1    2026  43.59375_-116.78125    ensembe_mean         92          2.336201   \n",
       "296  2027  43.59375_-116.78125    ensembe_mean         93          2.428946   \n",
       "\n",
       "     mean_escaped_Gen1  mean_escaped_Gen2  mean_escaped_Gen3  \\\n",
       "1            24.035184           27.50817           2.912981   \n",
       "296          26.711047           30.58016           2.788000   \n",
       "\n",
       "     mean_escaped_Gen4  mean_precip     mean_gdd  \n",
       "1             0.027137       260.75  3623.723188  \n",
       "296           0.000000       245.40  3713.421219  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick up one location data\n",
    "curr_location_df = future_orig[future_orig.location == future_orig.location.iloc[0]].copy()\n",
    "complete_hist_df = hist_orig.copy()\n",
    "curr_location_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_count = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_yr_count = curr_location_df.shape[0]\n",
    "needed_col_count = NN_count * 2\n",
    "\n",
    "NNs_df   = curr_location_df[['year', 'location']].copy() # data frame containing (year, location)\n",
    "dists_df = curr_location_df[['year', 'location']].copy() # data frame containing distances\n",
    "\n",
    "## concatenate new data frame to above ones, to speed up\n",
    "NNs_df_new_cols, dists_df_new_cols = create_colnames(NN_count)\n",
    "\n",
    "NNs_df_helper = pd.DataFrame('-999', index=NNs_df.index,  columns=NNs_df_new_cols)\n",
    "dists_df_helper = pd.DataFrame('-999', index=dists_df.index,  columns=dists_df_new_cols)\n",
    "\n",
    "NNs_df = pd.concat([NNs_df, NNs_df_helper], axis=1)\n",
    "dists_df = pd.concat([dists_df, dists_df_helper], axis=1)\n",
    "\n",
    "del(NNs_df_helper, dists_df_helper, NNs_df_new_cols, dists_df_new_cols)\n",
    "\n",
    "\n",
    "# form the ICV to compute its covariance to remove inter-annual variability\n",
    "ICV = complete_hist_df.copy()\n",
    "ICV = ICV.loc[ICV['location'] == curr_location_df.location.unique()[0]] # filter corresponding location\n",
    "\n",
    "ICV_means = ICV.loc[:, numeric_feat].mean()\n",
    "ICV_stds = ICV.loc[:, numeric_feat].std()\n",
    "ICV_stds[ICV_stds.le(10**(-10))] = 1\n",
    "ICV = (ICV.loc[:, numeric_feat] - ICV_means) / ICV_stds\n",
    "\n",
    "curr_location_df.loc[:, numeric_feat] = (curr_location_df.loc[:, numeric_feat] - ICV_means) / ICV_stds\n",
    "complete_hist_df.loc[:, numeric_feat]  = (complete_hist_df.loc[:, numeric_feat] - ICV_means) / ICV_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# pick numerical part of the data frame to do the operations:\n",
    "#\n",
    "complete_hist_df_numeric = complete_hist_df.loc[:, numeric_feat].copy()\n",
    "future_numeric = curr_location_df.loc[:, numeric_feat].copy()\n",
    "ICV = ICV.loc[:, numeric_feat]\n",
    "\n",
    "### Apply PCA here and use those to find analogs\n",
    "pca = PCA(n_components = detect_effective_compon(ICV))\n",
    "pca.fit(ICV);\n",
    "#\n",
    "# transform data into PCA space to compute analogs\n",
    "ICV_pca = pca.transform(ICV)\n",
    "hist_pca = pca.transform(complete_hist_df_numeric)\n",
    "future_pca = pca.transform(future_numeric)\n",
    "\n",
    "# the following is the same as [(1/N) * np.matmul(M.transpose(), M)]. which is not even divided by N-1\n",
    "cov = sklearn.covariance.empirical_covariance(ICV_pca, assume_centered=False)\n",
    "\n",
    "# there is no difference between the following line and adding metric_params={'V': cov} to it\n",
    "neigh = NearestNeighbors(n_neighbors=NN_count, metric = \"mahalanobis\", algorithm=\"brute\")\n",
    "neigh.fit(hist_pca);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr = 0\n",
    "result = neigh.kneighbors([future_pca[yr, ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNs_distances = result[0][0]\n",
    "NNs_idx = result[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_NNs = complete_hist_df.loc[NNs_idx, ['year', 'location']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_NNs = list(np.hstack(np.split(curr_NNs, n_ngbrs))[0])\n",
    "NNs_df.iloc[yr, 2:] = curr_NNs\n",
    "\n",
    "dists_df.iloc[yr, 2:] = NNs_distances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr = 1\n",
    "result = neigh.kneighbors([future_pca[yr, ]])\n",
    "\n",
    "NNs_distances = result[0][0]\n",
    "NNs_idx = result[1][0]\n",
    "\n",
    "# find and reshape the NNs\n",
    "# reshape the nearest neighbros from long to wide, so, every other column is (year, location) of ith NN\n",
    "#\n",
    "curr_NNs = complete_hist_df.loc[NNs_idx, ['year', 'location']].copy()\n",
    "curr_NNs = list(np.hstack(np.split(curr_NNs, NN_count))[0])\n",
    "NNs_df.iloc[yr, 2:] = curr_NNs\n",
    "\n",
    "dists_df.iloc[yr, 2:] = NNs_distances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>location</th>\n",
       "      <th>dist_NN_1</th>\n",
       "      <th>dist_NN_2</th>\n",
       "      <th>dist_NN_3</th>\n",
       "      <th>dist_NN_4</th>\n",
       "      <th>dist_NN_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.797874</td>\n",
       "      <td>0.804299</td>\n",
       "      <td>0.8108</td>\n",
       "      <td>0.886148</td>\n",
       "      <td>0.896228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2027</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.683017</td>\n",
       "      <td>0.849194</td>\n",
       "      <td>0.857648</td>\n",
       "      <td>0.875618</td>\n",
       "      <td>0.901377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>2028</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2029</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>2030</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year             location dist_NN_1 dist_NN_2 dist_NN_3 dist_NN_4  \\\n",
       "1     2026  43.59375_-116.78125  0.797874  0.804299    0.8108  0.886148   \n",
       "296   2027  43.59375_-116.78125  0.683017  0.849194  0.857648  0.875618   \n",
       "591   2028  43.59375_-116.78125      -999      -999      -999      -999   \n",
       "886   2029  43.59375_-116.78125      -999      -999      -999      -999   \n",
       "1181  2030  43.59375_-116.78125      -999      -999      -999      -999   \n",
       "\n",
       "     dist_NN_5  \n",
       "1     0.896228  \n",
       "296   0.901377  \n",
       "591       -999  \n",
       "886       -999  \n",
       "1181      -999  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ngbrs = 5\n",
    "neigh = NearestNeighbors(n_neighbors=n_ngbrs, metric = \"mahalanobis\", metric_params={'V': cov}, algorithm=\"brute\")\n",
    "neigh.fit(hist_pca);\n",
    "result = neigh.kneighbors([future_pca[1, ]])\n",
    "\n",
    "NNs_distances = result[0][0]\n",
    "\n",
    "# find and reshape the NNs\n",
    "# reshape the nearest neighbros from long to wide, so, every other column is (year, location) of ith NN\n",
    "#\n",
    "NNs_idx = result[1][0]\n",
    "curr_NNs = complete_hist_df.loc[NNs_idx, ['year', 'location']].copy()\n",
    "curr_NNs = pd.DataFrame(np.hstack(np.split(curr_NNs, NN_count)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNs_df.iloc[0, 2:12] = list(curr_NNs.iloc[0, ])\n",
    "NNs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_location_dist_builtin(curr_location_df, complete_hist_df, numeric_feat, NN_count):\n",
    "    future_yr_count = curr_location_df.shape[0]\n",
    "    needed_col_count = NN_count * 2\n",
    "    \n",
    "    NNs_df   = curr_location_df[['year', 'location']].copy() # data frame containing (year, location)\n",
    "    dists_df = curr_location_df[['year', 'location']].copy() # data frame containing distances\n",
    "    \n",
    "    ## concatenate new data frame to above ones, to speed up\n",
    "    NNs_df_new_cols, dists_df_new_cols = create_colnames(NN_count)\n",
    "    \n",
    "    NNs_df_helper = pd.DataFrame('-999', index=NNs_df.index,  columns=NNs_df_new_cols)\n",
    "    dists_df_helper = pd.DataFrame('-999', index=dists_df.index,  columns=dists_df_new_cols)\n",
    "    \n",
    "    NNs_df = pd.concat([NNs_df, NNs_df_helper], axis=1)\n",
    "    dists_df = pd.concat([dists_df, dists_df_helper], axis=1)\n",
    "    \n",
    "    del(NNs_df_helper, dists_df_helper, NNs_df_new_cols, dists_df_new_cols)\n",
    "    \n",
    "    \n",
    "    # form the ICV to compute its covariance to remove inter-annual variability\n",
    "    ICV = complete_hist_df.copy()\n",
    "    ICV = ICV.loc[ICV['location'] == curr_location_df.location.unique()[0]] # filter corresponding location\n",
    "    #############################################################################\n",
    "    #\n",
    "    #          Normalize before doing anything\n",
    "    #\n",
    "    #############################################################################\n",
    "    ICV_means = ICV.loc[:, numeric_feat].mean()\n",
    "    ICV_stds = ICV.loc[:, numeric_feat].std()\n",
    "    ICV_stds[ICV_stds.le(10**(-10))] = 1\n",
    "    \n",
    "    ICV = (ICV.loc[:, numeric_feat] - ICV_means) / ICV_stds\n",
    "    curr_location_df.loc[:, numeric_feat] = (curr_location_df.loc[:, numeric_feat] - ICV_means) / ICV_stds\n",
    "    complete_hist_df.loc[:, numeric_feat] = (complete_hist_df.loc[:, numeric_feat] - ICV_means) / ICV_stds\n",
    "    #\n",
    "    # pick numerical part of the data frame to do the operations:\n",
    "    #\n",
    "    complete_hist_df_numeric = complete_hist_df.loc[:, numeric_feat].copy()\n",
    "    future_numeric = curr_location_df.loc[:, numeric_feat].copy()\n",
    "    ICV = ICV.loc[:, numeric_feat]\n",
    "    \n",
    "    ### Apply PCA here and use those to find analogs\n",
    "    pca = PCA(n_components = detect_effective_compon(ICV))\n",
    "    pca.fit(ICV);\n",
    "    #\n",
    "    # transform data into PCA space to compute analogs\n",
    "    ICV_pca = pca.transform(ICV)\n",
    "    hist_pca = pca.transform(complete_hist_df_numeric)\n",
    "    future_pca = pca.transform(future_numeric)\n",
    "\n",
    "    # the following is the same as [(1/N) * np.matmul(M.transpose(), M)]. which is not even divided by N-1\n",
    "    cov = sklearn.covariance.empirical_covariance(ICV_pca, assume_centered=False)\n",
    "    \n",
    "    # there is no difference between the following line and adding metric_params={'V': cov} to it\n",
    "    neigh = NearestNeighbors(n_neighbors=NN_count, metric = \"mahalanobis\", algorithm=\"brute\")\n",
    "    neigh.fit(hist_pca);\n",
    "    for yr in np.arange(curr_location_df.shape[0]):\n",
    "        result = neigh.kneighbors([future_pca[yr, ]])\n",
    "\n",
    "        NNs_distances = result[0][0]\n",
    "        NNs_idx = result[1][0]\n",
    "\n",
    "        # find and reshape the NNs\n",
    "        # reshape the nearest neighbros from long to wide, so, every other column is (year, location) of ith NN\n",
    "        #\n",
    "        curr_NNs = complete_hist_df.loc[NNs_idx, ['year', 'location']].copy()\n",
    "        curr_NNs = list(np.hstack(np.split(curr_NNs, NN_count))[0])\n",
    "        NNs_df.iloc[yr, 2:] = curr_NNs\n",
    "        \n",
    "        dists_df.iloc[yr, 2:] = NNs_distances\n",
    "\n",
    "    return(NNs_df, dists_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = one_location_dist_builtin(curr_location_df, complete_hist_df, numeric_feat, NN_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>location</th>\n",
       "      <th>dist_NN_1</th>\n",
       "      <th>dist_NN_2</th>\n",
       "      <th>dist_NN_3</th>\n",
       "      <th>dist_NN_4</th>\n",
       "      <th>dist_NN_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.797874</td>\n",
       "      <td>0.804299</td>\n",
       "      <td>0.8108</td>\n",
       "      <td>0.886148</td>\n",
       "      <td>0.896228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2027</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.683017</td>\n",
       "      <td>0.849194</td>\n",
       "      <td>0.857648</td>\n",
       "      <td>0.875618</td>\n",
       "      <td>0.901377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>2028</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.613924</td>\n",
       "      <td>0.691352</td>\n",
       "      <td>0.692246</td>\n",
       "      <td>0.726502</td>\n",
       "      <td>0.734785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2029</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.9074</td>\n",
       "      <td>1.95769</td>\n",
       "      <td>1.9683</td>\n",
       "      <td>1.97954</td>\n",
       "      <td>1.98294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>2030</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.954512</td>\n",
       "      <td>0.994383</td>\n",
       "      <td>1.0683</td>\n",
       "      <td>1.10056</td>\n",
       "      <td>1.10398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>2031</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.671194</td>\n",
       "      <td>0.681865</td>\n",
       "      <td>0.690564</td>\n",
       "      <td>0.691943</td>\n",
       "      <td>0.696764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>2032</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.816631</td>\n",
       "      <td>0.926952</td>\n",
       "      <td>0.963989</td>\n",
       "      <td>0.988894</td>\n",
       "      <td>1.00898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>2033</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>2.01943</td>\n",
       "      <td>2.03389</td>\n",
       "      <td>2.07135</td>\n",
       "      <td>2.09749</td>\n",
       "      <td>2.1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>2034</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.02401</td>\n",
       "      <td>1.04326</td>\n",
       "      <td>1.06528</td>\n",
       "      <td>1.12587</td>\n",
       "      <td>1.14767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>2035</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.742176</td>\n",
       "      <td>0.800303</td>\n",
       "      <td>0.878685</td>\n",
       "      <td>0.882782</td>\n",
       "      <td>0.886884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>2036</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.956582</td>\n",
       "      <td>1.12163</td>\n",
       "      <td>1.13471</td>\n",
       "      <td>1.2589</td>\n",
       "      <td>1.27433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>2037</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.835162</td>\n",
       "      <td>0.900767</td>\n",
       "      <td>0.906834</td>\n",
       "      <td>0.925733</td>\n",
       "      <td>0.930818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>2038</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.750301</td>\n",
       "      <td>0.85865</td>\n",
       "      <td>0.880936</td>\n",
       "      <td>0.915513</td>\n",
       "      <td>0.941658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>2039</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.03542</td>\n",
       "      <td>1.1455</td>\n",
       "      <td>1.17874</td>\n",
       "      <td>1.18476</td>\n",
       "      <td>1.21502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>2040</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.29803</td>\n",
       "      <td>1.40559</td>\n",
       "      <td>1.41474</td>\n",
       "      <td>1.42013</td>\n",
       "      <td>1.43438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>2041</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.912672</td>\n",
       "      <td>1.07076</td>\n",
       "      <td>1.10286</td>\n",
       "      <td>1.10585</td>\n",
       "      <td>1.12004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>2042</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.36797</td>\n",
       "      <td>1.3707</td>\n",
       "      <td>1.44866</td>\n",
       "      <td>1.54904</td>\n",
       "      <td>1.55407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>2043</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.868016</td>\n",
       "      <td>0.975711</td>\n",
       "      <td>1.05992</td>\n",
       "      <td>1.06499</td>\n",
       "      <td>1.07013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>2044</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.1135</td>\n",
       "      <td>1.11831</td>\n",
       "      <td>1.149</td>\n",
       "      <td>1.14933</td>\n",
       "      <td>1.15011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5606</th>\n",
       "      <td>2045</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.83202</td>\n",
       "      <td>2.00359</td>\n",
       "      <td>2.00582</td>\n",
       "      <td>2.01252</td>\n",
       "      <td>2.01322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5901</th>\n",
       "      <td>2046</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.413577</td>\n",
       "      <td>0.433662</td>\n",
       "      <td>0.442195</td>\n",
       "      <td>0.46767</td>\n",
       "      <td>0.468998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6196</th>\n",
       "      <td>2047</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.04827</td>\n",
       "      <td>1.06481</td>\n",
       "      <td>1.07807</td>\n",
       "      <td>1.11512</td>\n",
       "      <td>1.14167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>2048</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.63233</td>\n",
       "      <td>1.63924</td>\n",
       "      <td>1.64348</td>\n",
       "      <td>1.64457</td>\n",
       "      <td>1.64787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6786</th>\n",
       "      <td>2049</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.12515</td>\n",
       "      <td>1.15555</td>\n",
       "      <td>1.15769</td>\n",
       "      <td>1.16274</td>\n",
       "      <td>1.1669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7081</th>\n",
       "      <td>2050</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.99488</td>\n",
       "      <td>2.11411</td>\n",
       "      <td>2.17219</td>\n",
       "      <td>2.26489</td>\n",
       "      <td>2.28438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>2051</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.43463</td>\n",
       "      <td>1.54561</td>\n",
       "      <td>1.55788</td>\n",
       "      <td>1.6348</td>\n",
       "      <td>1.65942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7671</th>\n",
       "      <td>2052</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.940664</td>\n",
       "      <td>1.18088</td>\n",
       "      <td>1.20188</td>\n",
       "      <td>1.23788</td>\n",
       "      <td>1.24793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7966</th>\n",
       "      <td>2053</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>2.2175</td>\n",
       "      <td>2.24439</td>\n",
       "      <td>2.26942</td>\n",
       "      <td>2.2963</td>\n",
       "      <td>2.35066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8261</th>\n",
       "      <td>2054</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.36125</td>\n",
       "      <td>1.72444</td>\n",
       "      <td>1.73294</td>\n",
       "      <td>1.7349</td>\n",
       "      <td>1.74966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8556</th>\n",
       "      <td>2055</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.61749</td>\n",
       "      <td>1.73763</td>\n",
       "      <td>1.73766</td>\n",
       "      <td>1.7401</td>\n",
       "      <td>1.74905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11801</th>\n",
       "      <td>2066</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>2.26236</td>\n",
       "      <td>2.40442</td>\n",
       "      <td>2.42745</td>\n",
       "      <td>2.45718</td>\n",
       "      <td>2.46032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12096</th>\n",
       "      <td>2067</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.862237</td>\n",
       "      <td>1.05786</td>\n",
       "      <td>1.17204</td>\n",
       "      <td>1.17654</td>\n",
       "      <td>1.1906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12391</th>\n",
       "      <td>2068</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>2.12603</td>\n",
       "      <td>2.13316</td>\n",
       "      <td>2.13319</td>\n",
       "      <td>2.14871</td>\n",
       "      <td>2.15958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12686</th>\n",
       "      <td>2069</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>2.2405</td>\n",
       "      <td>2.28086</td>\n",
       "      <td>2.32567</td>\n",
       "      <td>2.3283</td>\n",
       "      <td>2.37308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12981</th>\n",
       "      <td>2070</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>2.5184</td>\n",
       "      <td>2.62105</td>\n",
       "      <td>2.73063</td>\n",
       "      <td>2.78013</td>\n",
       "      <td>2.86867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13276</th>\n",
       "      <td>2071</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>2.1092</td>\n",
       "      <td>2.28981</td>\n",
       "      <td>2.40218</td>\n",
       "      <td>2.41569</td>\n",
       "      <td>2.50829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13571</th>\n",
       "      <td>2072</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.56453</td>\n",
       "      <td>1.57854</td>\n",
       "      <td>1.7068</td>\n",
       "      <td>1.71842</td>\n",
       "      <td>1.72061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13866</th>\n",
       "      <td>2073</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>2.43864</td>\n",
       "      <td>2.49793</td>\n",
       "      <td>2.51415</td>\n",
       "      <td>2.52539</td>\n",
       "      <td>2.60081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14161</th>\n",
       "      <td>2074</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>2.46574</td>\n",
       "      <td>2.58408</td>\n",
       "      <td>2.58875</td>\n",
       "      <td>2.62692</td>\n",
       "      <td>2.62847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14456</th>\n",
       "      <td>2075</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>2.12461</td>\n",
       "      <td>2.17806</td>\n",
       "      <td>2.24238</td>\n",
       "      <td>2.24663</td>\n",
       "      <td>2.26296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14751</th>\n",
       "      <td>2076</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.84836</td>\n",
       "      <td>1.97105</td>\n",
       "      <td>2.1402</td>\n",
       "      <td>2.15536</td>\n",
       "      <td>2.18359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15046</th>\n",
       "      <td>2077</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.41669</td>\n",
       "      <td>1.46526</td>\n",
       "      <td>1.56554</td>\n",
       "      <td>1.58518</td>\n",
       "      <td>1.59058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15341</th>\n",
       "      <td>2078</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.68433</td>\n",
       "      <td>1.90807</td>\n",
       "      <td>2.02378</td>\n",
       "      <td>2.05212</td>\n",
       "      <td>2.07702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15636</th>\n",
       "      <td>2079</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.46168</td>\n",
       "      <td>1.51054</td>\n",
       "      <td>1.51956</td>\n",
       "      <td>1.53817</td>\n",
       "      <td>1.54463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15931</th>\n",
       "      <td>2080</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>2.00981</td>\n",
       "      <td>2.0654</td>\n",
       "      <td>2.13704</td>\n",
       "      <td>2.14094</td>\n",
       "      <td>2.14513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16226</th>\n",
       "      <td>2081</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.81907</td>\n",
       "      <td>1.87392</td>\n",
       "      <td>1.94255</td>\n",
       "      <td>1.97295</td>\n",
       "      <td>1.97915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16521</th>\n",
       "      <td>2082</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.84589</td>\n",
       "      <td>1.96008</td>\n",
       "      <td>1.96495</td>\n",
       "      <td>1.99505</td>\n",
       "      <td>2.03432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16816</th>\n",
       "      <td>2083</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>0.942415</td>\n",
       "      <td>1.08523</td>\n",
       "      <td>1.10101</td>\n",
       "      <td>1.11027</td>\n",
       "      <td>1.11698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17111</th>\n",
       "      <td>2084</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.43394</td>\n",
       "      <td>1.52798</td>\n",
       "      <td>1.531</td>\n",
       "      <td>1.53572</td>\n",
       "      <td>1.53758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17406</th>\n",
       "      <td>2085</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.58432</td>\n",
       "      <td>1.58527</td>\n",
       "      <td>1.58706</td>\n",
       "      <td>1.5923</td>\n",
       "      <td>1.59342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17701</th>\n",
       "      <td>2086</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.64582</td>\n",
       "      <td>1.76248</td>\n",
       "      <td>1.81345</td>\n",
       "      <td>1.82472</td>\n",
       "      <td>1.83001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>2087</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.89124</td>\n",
       "      <td>1.94682</td>\n",
       "      <td>1.95431</td>\n",
       "      <td>1.96048</td>\n",
       "      <td>1.99907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18291</th>\n",
       "      <td>2088</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.85861</td>\n",
       "      <td>1.87102</td>\n",
       "      <td>1.87913</td>\n",
       "      <td>1.91768</td>\n",
       "      <td>1.91933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18586</th>\n",
       "      <td>2089</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.86166</td>\n",
       "      <td>1.89239</td>\n",
       "      <td>1.94126</td>\n",
       "      <td>1.94241</td>\n",
       "      <td>1.95094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18881</th>\n",
       "      <td>2090</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.711</td>\n",
       "      <td>1.87865</td>\n",
       "      <td>1.96576</td>\n",
       "      <td>2.06314</td>\n",
       "      <td>2.07413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19176</th>\n",
       "      <td>2091</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.82197</td>\n",
       "      <td>1.82763</td>\n",
       "      <td>1.89531</td>\n",
       "      <td>1.91184</td>\n",
       "      <td>1.96109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19471</th>\n",
       "      <td>2092</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>2.34188</td>\n",
       "      <td>2.57037</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.60573</td>\n",
       "      <td>2.61083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19766</th>\n",
       "      <td>2093</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.7021</td>\n",
       "      <td>1.73165</td>\n",
       "      <td>1.80823</td>\n",
       "      <td>1.85861</td>\n",
       "      <td>1.86859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20061</th>\n",
       "      <td>2094</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>2.16846</td>\n",
       "      <td>2.19323</td>\n",
       "      <td>2.25432</td>\n",
       "      <td>2.27442</td>\n",
       "      <td>2.30202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20356</th>\n",
       "      <td>2095</td>\n",
       "      <td>43.59375_-116.78125</td>\n",
       "      <td>1.66809</td>\n",
       "      <td>1.73105</td>\n",
       "      <td>1.75842</td>\n",
       "      <td>1.76164</td>\n",
       "      <td>1.77923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year             location dist_NN_1 dist_NN_2 dist_NN_3 dist_NN_4  \\\n",
       "1      2026  43.59375_-116.78125  0.797874  0.804299    0.8108  0.886148   \n",
       "296    2027  43.59375_-116.78125  0.683017  0.849194  0.857648  0.875618   \n",
       "591    2028  43.59375_-116.78125  0.613924  0.691352  0.692246  0.726502   \n",
       "886    2029  43.59375_-116.78125    1.9074   1.95769    1.9683   1.97954   \n",
       "1181   2030  43.59375_-116.78125  0.954512  0.994383    1.0683   1.10056   \n",
       "1476   2031  43.59375_-116.78125  0.671194  0.681865  0.690564  0.691943   \n",
       "1771   2032  43.59375_-116.78125  0.816631  0.926952  0.963989  0.988894   \n",
       "2066   2033  43.59375_-116.78125   2.01943   2.03389   2.07135   2.09749   \n",
       "2361   2034  43.59375_-116.78125   1.02401   1.04326   1.06528   1.12587   \n",
       "2656   2035  43.59375_-116.78125  0.742176  0.800303  0.878685  0.882782   \n",
       "2951   2036  43.59375_-116.78125  0.956582   1.12163   1.13471    1.2589   \n",
       "3246   2037  43.59375_-116.78125  0.835162  0.900767  0.906834  0.925733   \n",
       "3541   2038  43.59375_-116.78125  0.750301   0.85865  0.880936  0.915513   \n",
       "3836   2039  43.59375_-116.78125   1.03542    1.1455   1.17874   1.18476   \n",
       "4131   2040  43.59375_-116.78125   1.29803   1.40559   1.41474   1.42013   \n",
       "4426   2041  43.59375_-116.78125  0.912672   1.07076   1.10286   1.10585   \n",
       "4721   2042  43.59375_-116.78125   1.36797    1.3707   1.44866   1.54904   \n",
       "5016   2043  43.59375_-116.78125  0.868016  0.975711   1.05992   1.06499   \n",
       "5311   2044  43.59375_-116.78125    1.1135   1.11831     1.149   1.14933   \n",
       "5606   2045  43.59375_-116.78125   1.83202   2.00359   2.00582   2.01252   \n",
       "5901   2046  43.59375_-116.78125  0.413577  0.433662  0.442195   0.46767   \n",
       "6196   2047  43.59375_-116.78125   1.04827   1.06481   1.07807   1.11512   \n",
       "6491   2048  43.59375_-116.78125   1.63233   1.63924   1.64348   1.64457   \n",
       "6786   2049  43.59375_-116.78125   1.12515   1.15555   1.15769   1.16274   \n",
       "7081   2050  43.59375_-116.78125   1.99488   2.11411   2.17219   2.26489   \n",
       "7376   2051  43.59375_-116.78125   1.43463   1.54561   1.55788    1.6348   \n",
       "7671   2052  43.59375_-116.78125  0.940664   1.18088   1.20188   1.23788   \n",
       "7966   2053  43.59375_-116.78125    2.2175   2.24439   2.26942    2.2963   \n",
       "8261   2054  43.59375_-116.78125   1.36125   1.72444   1.73294    1.7349   \n",
       "8556   2055  43.59375_-116.78125   1.61749   1.73763   1.73766    1.7401   \n",
       "...     ...                  ...       ...       ...       ...       ...   \n",
       "11801  2066  43.59375_-116.78125   2.26236   2.40442   2.42745   2.45718   \n",
       "12096  2067  43.59375_-116.78125  0.862237   1.05786   1.17204   1.17654   \n",
       "12391  2068  43.59375_-116.78125   2.12603   2.13316   2.13319   2.14871   \n",
       "12686  2069  43.59375_-116.78125    2.2405   2.28086   2.32567    2.3283   \n",
       "12981  2070  43.59375_-116.78125    2.5184   2.62105   2.73063   2.78013   \n",
       "13276  2071  43.59375_-116.78125    2.1092   2.28981   2.40218   2.41569   \n",
       "13571  2072  43.59375_-116.78125   1.56453   1.57854    1.7068   1.71842   \n",
       "13866  2073  43.59375_-116.78125   2.43864   2.49793   2.51415   2.52539   \n",
       "14161  2074  43.59375_-116.78125   2.46574   2.58408   2.58875   2.62692   \n",
       "14456  2075  43.59375_-116.78125   2.12461   2.17806   2.24238   2.24663   \n",
       "14751  2076  43.59375_-116.78125   1.84836   1.97105    2.1402   2.15536   \n",
       "15046  2077  43.59375_-116.78125   1.41669   1.46526   1.56554   1.58518   \n",
       "15341  2078  43.59375_-116.78125   1.68433   1.90807   2.02378   2.05212   \n",
       "15636  2079  43.59375_-116.78125   1.46168   1.51054   1.51956   1.53817   \n",
       "15931  2080  43.59375_-116.78125   2.00981    2.0654   2.13704   2.14094   \n",
       "16226  2081  43.59375_-116.78125   1.81907   1.87392   1.94255   1.97295   \n",
       "16521  2082  43.59375_-116.78125   1.84589   1.96008   1.96495   1.99505   \n",
       "16816  2083  43.59375_-116.78125  0.942415   1.08523   1.10101   1.11027   \n",
       "17111  2084  43.59375_-116.78125   1.43394   1.52798     1.531   1.53572   \n",
       "17406  2085  43.59375_-116.78125   1.58432   1.58527   1.58706    1.5923   \n",
       "17701  2086  43.59375_-116.78125   1.64582   1.76248   1.81345   1.82472   \n",
       "17996  2087  43.59375_-116.78125   1.89124   1.94682   1.95431   1.96048   \n",
       "18291  2088  43.59375_-116.78125   1.85861   1.87102   1.87913   1.91768   \n",
       "18586  2089  43.59375_-116.78125   1.86166   1.89239   1.94126   1.94241   \n",
       "18881  2090  43.59375_-116.78125     1.711   1.87865   1.96576   2.06314   \n",
       "19176  2091  43.59375_-116.78125   1.82197   1.82763   1.89531   1.91184   \n",
       "19471  2092  43.59375_-116.78125   2.34188   2.57037       2.6   2.60573   \n",
       "19766  2093  43.59375_-116.78125    1.7021   1.73165   1.80823   1.85861   \n",
       "20061  2094  43.59375_-116.78125   2.16846   2.19323   2.25432   2.27442   \n",
       "20356  2095  43.59375_-116.78125   1.66809   1.73105   1.75842   1.76164   \n",
       "\n",
       "      dist_NN_5  \n",
       "1      0.896228  \n",
       "296    0.901377  \n",
       "591    0.734785  \n",
       "886     1.98294  \n",
       "1181    1.10398  \n",
       "1476   0.696764  \n",
       "1771    1.00898  \n",
       "2066     2.1357  \n",
       "2361    1.14767  \n",
       "2656   0.886884  \n",
       "2951    1.27433  \n",
       "3246   0.930818  \n",
       "3541   0.941658  \n",
       "3836    1.21502  \n",
       "4131    1.43438  \n",
       "4426    1.12004  \n",
       "4721    1.55407  \n",
       "5016    1.07013  \n",
       "5311    1.15011  \n",
       "5606    2.01322  \n",
       "5901   0.468998  \n",
       "6196    1.14167  \n",
       "6491    1.64787  \n",
       "6786     1.1669  \n",
       "7081    2.28438  \n",
       "7376    1.65942  \n",
       "7671    1.24793  \n",
       "7966    2.35066  \n",
       "8261    1.74966  \n",
       "8556    1.74905  \n",
       "...         ...  \n",
       "11801   2.46032  \n",
       "12096    1.1906  \n",
       "12391   2.15958  \n",
       "12686   2.37308  \n",
       "12981   2.86867  \n",
       "13276   2.50829  \n",
       "13571   1.72061  \n",
       "13866   2.60081  \n",
       "14161   2.62847  \n",
       "14456   2.26296  \n",
       "14751   2.18359  \n",
       "15046   1.59058  \n",
       "15341   2.07702  \n",
       "15636   1.54463  \n",
       "15931   2.14513  \n",
       "16226   1.97915  \n",
       "16521   2.03432  \n",
       "16816   1.11698  \n",
       "17111   1.53758  \n",
       "17406   1.59342  \n",
       "17701   1.83001  \n",
       "17996   1.99907  \n",
       "18291   1.91933  \n",
       "18586   1.95094  \n",
       "18881   2.07413  \n",
       "19176   1.96109  \n",
       "19471   2.61083  \n",
       "19766   1.86859  \n",
       "20061   2.30202  \n",
       "20356   1.77923  \n",
       "\n",
       "[70 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_location_dist(curr_location_df, complete_hist_df, numeric_feat, NN_count):\n",
    "    \"\"\"\n",
    "    input: curr_location_df: data frame of current location, including one location, all future years\n",
    "           complete_hist_df: historical data frame (analog pool)\n",
    "           numeric_feat: list of column names that are numeric\n",
    "           NN_count: number of NNs we want\n",
    "    \n",
    "    output: two data frames:\n",
    "                includes list of years and locations of nearest neighbors\n",
    "                includes list of distaces of NNs to the queries.\n",
    "    \"\"\"\n",
    "\n",
    "    # initiatae data frames to attach the locations that are NNs\n",
    "    NNs_df   = curr_location_df[['year', 'location']].copy() # data frame containing (year, location)\n",
    "    dists_df = curr_location_df[['year', 'location']].copy() # data frame containing distances\n",
    "    \"\"\"\n",
    "    ## Make the ICV\n",
    "    Copy all the historical data into `ICV` so they are separate\n",
    "    and we are clear on what is going on\n",
    "\n",
    "    `ICV` is used to remove inter anual variability! \n",
    "    This is the one we have to get covariance matrix from.\n",
    "    \"\"\"\n",
    "    \n",
    "    # form the ICV to compute its covariance to remove inter-annual variability\n",
    "    ICV = complete_hist_df.copy()\n",
    "    ICV = ICV.loc[ICV['location'] == curr_location_df.location.unique()[0]] # filter corresponding location\n",
    "    #############################################################################\n",
    "    #\n",
    "    #          Normalize before doing anything\n",
    "    #\n",
    "    #############################################################################\n",
    "    ICV_means = curr_location_df.loc[:, numeric_feat].mean()\n",
    "    ICV_stds = curr_location_df.loc[:, numeric_feat].std()\n",
    "    \n",
    "    ICV = (ICV.loc[:, numeric_feat] - ICV_means) / ICV_stds\n",
    "    curr_location_df = (curr_location_df.loc[:, numeric_feat] - ICV_means) / ICV_stds\n",
    "    complete_hist_df = (complete_hist_df.loc[:, numeric_feat] - ICV_means) / ICV_stds\n",
    "    \n",
    "    #\n",
    "    # pick numerical part of the data frame to do the operations:\n",
    "    #\n",
    "    complete_hist_df_numeric = complete_hist_df.loc[:, numeric_feat].copy()\n",
    "    future_numeric = curr_location_df.loc[:, numeric_feat].copy()\n",
    "    ICV = ICV.loc[:, numeric_feat]\n",
    "    \n",
    "    ### Apply PCA here and use those to find analogs\n",
    "    pca = PCA(n_components = detect_effective_compon(ICV))\n",
    "    pca.fit(ICV)\n",
    "    #\n",
    "    # transform data into PCA space to compute analogs\n",
    "    ICV_pca = pca.transform(ICV)\n",
    "    hist_pca = pca.transform(complete_hist_df_numeric)\n",
    "    future_pca = pca.transform(future_numeric)\n",
    "    \n",
    "    # compute covariance of ICV_pca\n",
    "    # the robust thing changes every time! is it based on a random start\n",
    "    # of an interative method?\n",
    "    \"\"\"\n",
    "    robust_cov = MinCovDet().fit(ICV_pca)\n",
    "    robust_cov = robust_cov.covariance_\n",
    "    robust_cov_inv = np.linalg.inv(robust_cov)\n",
    "    # np.cov(ICV_pca);\n",
    "    \"\"\"\n",
    "    # the following is the same as [(1/N) * np.matmul(M.transpose(), M)]. which is not even divided by N-1\n",
    "    cov = sklearn.covariance.empirical_covariance(ICV_pca, assume_centered=False)\n",
    "    cov_inv = np.linalg.inv(cov)\n",
    "    ##\n",
    "    ## Find nearest neighbors\n",
    "    ##\n",
    "    future_yr_count = len(curr_location_df.year.unique())\n",
    "    \n",
    "    for yr in np.arange(future_yr_count):\n",
    "        # list of years and locations in historical data to use to attach the distances to\n",
    "        hist_loc_year_frame = complete_hist_df[['year', 'location']].copy()\n",
    "        \n",
    "        curr_ft = future_pca[yr, ]\n",
    "        curr_dists = one_sample_dist(curr_future=curr_ft, hist_dt=hist_pca, conar_inv=cov_inv)\n",
    "       \n",
    "        # add the distanced to the year_location data frame, \n",
    "        # so we know how far each point is from the query.\n",
    "        hist_loc_year_frame['distance'] = curr_distance\n",
    "        hist_loc_year_frame = hist_loc_year_frame.sort_values(by=\"distance\") \n",
    "        hist_loc_year_frame = hist_loc_year_frame.iloc[0: NN_count,] # grab needed number of nearest neighbors\n",
    "        \n",
    "        \n",
    "###################################################################################\n",
    "#                                                                                 #\n",
    "#        compute distance of one sample point to all points in analog pool        #\n",
    "#                                                                                 #\n",
    "###################################################################################\n",
    "def one_sample_dist(curr_future, hist_dt, conar_inv):\n",
    "    \"\"\"\n",
    "    inputs here are of np.ndarray type that are projections into PCA space\n",
    "    \n",
    "    inputs: curr_future: future data for one location, one year (a vector)\n",
    "            hist_dt: historical data to find analogs in\n",
    "            conar_inv: inverse of covariance matrix for M. distance\n",
    "\n",
    "    output: list of distances of the given sample, (one_loc, one_year),\n",
    "            from all historical samples. \n",
    "            (1293 locations * 37 years = 47841 distances)\n",
    "    \"\"\"\n",
    "    diff_matrix = curr_future - hist_dt\n",
    "    square_dists_matrix = np.matmul(diff_matrix, np.matmul(conar_inv, diff_matrix.transpose()))\n",
    "\n",
    "    # take diagonal entries which are distances^2, and then take the sqrt.\n",
    "    distances = np.sqrt(np.diagonal(square_dists_matrix))\n",
    "    return (distances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
